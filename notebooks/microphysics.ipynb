{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for Earth System Science Hackathon 2020\n",
    "# Microphysics Machine Learning Challenge Problem\n",
    "\n",
    "Andrew Gettelman, Jack Chen, David John Gagne\n",
    "\n",
    "## Introduction\n",
    "Cloud processes are perhaps the most critical and uncertain processes for weather and climate prediction. The complex nature of sub grid scale clouds makes traceable simulation of clouds across scales difficult (or impossible). There exist many observations and detailed simulations of clouds that are used to develop and evaluate larger scale models. Many times these models and measurements are used to develop empirical relationships for large scale models to be computationally efficient. Machine learning provides another potential tool to improve our empirical parameterizations of clouds. Here we present a comprehensive investigation of replacing the warm rain formation process in an earth system model with emulators that use detailed treatments from small scale and idealized models to represent key cloud microphysical processes. \n",
    "\n",
    "The warm rain formation process is critical for weather and climate prediction. When rain forms governs the location, intensity and duration of rainfall events, critical for weather and the hydrologic cycle. Rain formation also affects cloud lifetime and the radiative properties of low clouds, making it critical for predicting climate (twomey1977,albrecht1989) The specific process of rain formation is altered by the microphysical properties of clouds, making rain formation susceptible to the size distribution of cloud drops, and ultimately to the distribution of aerosol particles that act as Cloud Condensation Nuclei. \n",
    "\n",
    "Ice of course will complicate the precipitation process. Supercooled liquid drops can exist, and these will either precipitation in a similar manner to warm precipitation (with no ice involved) and subsequently may freeze once they are rain drops. Or cloud droplets may freeze and form ice crystals, which precipitate and collect liquid, freezing or riming as they fall. We will not concern ourselves in this work with processes involving (or potentially involving) ice. This of course is a critical issue for weather (forbes2014)and climate (gettelman2019b,bodas-salcedo2019)prediction. \n",
    "\n",
    "The representation of rain formation in clouds involves the interaction of a population of hydrometeors. For warm clouds, the process is one of collision and coalescence, usually defined with a detailed process of stochastic collection (pruppacher1997). The stochastic collection process describes how each size particle interacts with other sizes. Usually there is a distribution of small cloud drops with an extension or separate distribution of rain drops whose interactions are evaluated. \n",
    "\n",
    "The stochastic collection process is computationally expensive to treat directly in large scale global models for weather and climate prediction. It requires the pre-computation of a collection kernel for how different sizes of hydrometeors will interact due to differential fall speeds, and it requires tracking populations discretized by bins. This tracking and advection of the order of 60 different bins for liquid and ice combined makes it computationally expensive. So traditionally, large scale models with bulk microphysics treat the stochastic collection process of warm rain formation in a heavily parameterized fashion (khairoutdinov2000,seifert200) For conceptual simplicity, the process is often broken up into two processes. Autoconversion is the transition of cloud drops into rain as part of a cloud droplet distribution grows to large sizes. Methods for determining autoconversion and accretion are varied. Because they are the major loss mechanism for cloud water different descriptions of the processes result in very different model evolution and climates (michibata2015).\n",
    "\n",
    "Because many methods for autoconversion and accretion are just empirical fits to data or other models, they are readily applicable to replacement with more sophisticated tools. Neural Networks are multivariate emulators that allow many more degrees of freedom than traditional polynomial methods for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Requirements\n",
    "This notebook requires Python >= 3.7. The following libraries are required:\n",
    "* numpy\n",
    "* scipy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* xarray\n",
    "* scikit-learn\n",
    "* tensorflow >= 2.1\n",
    "* netcdf4\n",
    "* h5netcdf\n",
    "* tqdm\n",
    "* pyyaml\n",
    "* s3fs\n",
    "* pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.17.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: xarray in /opt/conda/lib/python3.7/site-packages (0.15.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (0.23.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: netcdf4 in /opt/conda/lib/python3.7/site-packages (1.5.3)\n",
      "Requirement already satisfied: h5netcdf in /opt/conda/lib/python3.7/site-packages (0.8.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.46.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (5.3.1)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (0.17.1)\n",
      "Requirement already satisfied: mlmicrophysics in /home/jovyan/.local/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=41.2 in /opt/conda/lib/python3.7/site-packages (from xarray) (47.1.1.post20200529)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: cftime in /opt/conda/lib/python3.7/site-packages (from netcdf4) (1.1.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from s3fs) (0.7.4)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /opt/conda/lib/python3.7/site-packages (from s3fs) (1.17.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.18.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (1.25.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from botocore>=1.12.91->s3fs) (0.10.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy pandas matplotlib xarray scikit-learn tensorflow netcdf4 h5netcdf tqdm pyyaml s3fs pyarrow mlmicrophysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /opt/conda/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.17.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-95961938fea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if working on google colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install -U -q PyDrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# if working on google colab\n",
    "! pip install -U -q PyDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The Community Atmosphere Model version 6 (CAM6) is the atmospheric component of the Community Earth System Model version 2 (danabasoglu2020). CAM6 features a two-moment stratiform cloud microphysics scheme [hereafter MG2](gettelman2015b,gettelman2015a) with prognostic liquid, ice, rain and snow hydrometeor classes. MG2 permits ice supersaturation. CAM6 includes a physically based ice mixed phase dust ice nucleation scheme (hoose2010) with modifications for a distribution of contact angles (wang2014), and accounts for preexisting ice in the cirrus ice nucleation of (liu2005) as described by (shi2015).\n",
    "\n",
    "MG2 is coupled to a unified moist turbulence scheme, Cloud Layers Unified by Binormals (CLUBB), developed by (golaz2002) and (larson2002) and implemented in CAM by (bogenschutz2013). CLUBB handles stratiform clouds, boundary layer moist turbulence and shallow convective motions. CAM6 also has an ensemble plume mass flux deep convection scheme described by (zhang1995) and (neale2008), which has very simple microphysics. The radiation scheme is The Rapid Radiative Transfer Model for General Circulation Models (RRTMG) (iacono2000).\n",
    "\n",
    "Within the MG2 parameterization, the warm rain formation process is represented by equations for autoconversion and accretion from (khairoutdinov2000), hereafter KK2000. KK2000 uses empirical fits to a large eddy simulation with bin-resolved microphysics to define:\n",
    "\\begin{equation}\n",
    "    \\left(\\frac{\\partial q_r}{\\partial t} \\right)_{AUTO} = 13.5 q_c^{2.47} N_c^{-1.1}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\left(\\frac{\\partial q_r}{\\partial t} \\right)_{ACCRE} = 67 (q_c q_r)^{1.15}\n",
    "\\end{equation}\n",
    "Where $q_c$ and $q_r$ are mass mixing ratios for condensate and rain, and $N_c$ is the number concentration of condensate. For CAM6 the autconversion rate exponent and prefactor has been adjusted from the original (khairoutdinov2000) scheme to better match observations (gettelman2019b).\n",
    "\n",
    "#### Stochastic Collection\n",
    "\n",
    "We replace the KK2000 process rate equations with an estimate of the stochastic collection process from the Tel Aviv University (TAU) model. The TAU model uses a \"bin\" or \"sectional\" approach, where the drop size distribution is resolved into 35 size bins. It differs from most other microphysical codes in that it solves for two  moments of the drop size distribution in each of the bins. This allows for a more accurate transfer of mass between bins and alleviates anomalous drop growth. The original components were developed by Tzivion et al. (1987), (1989), Feingold et al. (1988) with later applications and development documented in Reisin et al. (1996), Stevens et al. (1996), Feingold et al. (1999), Tzivion et al. (1999), Yin et al (2000) and Harrington et al. (2000). \n",
    "\n",
    "Cloud Parcel Model Documentation here: https://www.esrl.noaa.gov/csl/staff/graham.feingold/code/readme.html\n",
    "\n",
    "First we convert the size distributions for liquid and rain into number concentrations in individual size bins. Liquid and rain are put in the same continuous distribution of 32 size bins for the TAU code. Then we use this as input to the TAU code, running the stochastic collection kernel. The result is a revised set of 32 bins with number concentration in each bin. We the find a minimum in the distribution if present: this is always found in the case where there is rain and condensate present at the end of the calculation. The minimum is typically between 40 and 100 microns (diameter). This minimium is used to divide the bins into liquid and rain. The total number and mass in each is defined, and tendencies calculated as the final mass and number minus the initial mass and number divided by the timestep. A limiter is applied to ensure that the mass and number are non-zero, and tendencies limited to ensure this. This estimated stochastic collection tendency is then applied instead of the accretion and autoconversion tendencies.\n",
    "\n",
    "The code does run the accretion and autoconversion from MG2 on the same state, and we can save this off as a diagnostic, so we can directly compare the original MG2 tendency (autoconversion + accretion) with the stochastic collection tendency from the TAU code. \n",
    "\n",
    "The microphysics datasets contains 176 files containing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time span of the dataset\n",
    "|  | Datetime |\n",
    "| ---- | :----:|\n",
    "| Start    | Jan 1     |\n",
    "| Length   | 2 years   |\n",
    "\n",
    "### Geographic Coverage of Dataset\n",
    "|  | Latitude | Longitude |\n",
    "| ------------- | :----:|:----------- |\n",
    "| Max      | 90     | 358.75 |\n",
    "| Min      | -90    | 0 |\n",
    "\n",
    "### Potential Input Variables\n",
    "| Variable Name | Units | Description |\n",
    "| ------------- | :----:|:----------- |\n",
    "| QC_TAU_in      | kg/kg     | cloud water mixing ratio |\n",
    "| NC_TAU_in      | kg<sup>-1</sup>     | cloud droplet column concentration |\n",
    "| QR_TAU_in      | kg/kg     | rain water mixing ratio |\n",
    "| NR_TAU_in      | kg<sup>-1</sup>     | rain droplet column concentration |\n",
    "| RHO_CLUBB_lev  | kg/m<sup>3</sup>     | air density at center of grid cell |\n",
    "\n",
    "### Output Variables\n",
    "| Variable Name | Units | Description |\n",
    "| ------------- | :----:|:----------- |\n",
    "| qrtend_TAU      | kg/kg/s     | qr tendency due to autoconversion & accretion in TAU bin |\n",
    "| nrtend_TAU      | kg/kg/s     | nr tendency due to autoconversion & accretion in TAU bin |\n",
    "| nctend_TAU      | kg/kg/s     | nc tendency due to autoconversion & accretion in TAU bin |\n",
    "\n",
    "### Meta Variables\n",
    "| Variable Name | Units | Description |\n",
    "| ------------- | :----:|:----------- |\n",
    "| lat      | degrees_north     | latitude |\n",
    "| lev      | hPa     | atmospheric level |\n",
    "| lon      | degrees_east     | longitude |\n",
    "| depth      | arbitrary     | depth index |\n",
    "| row      | arbitrary     | row index |\n",
    "| col      | arbitrary     | column index |\n",
    "| pressure      | Pa     | atmospheric pressure |\n",
    "| temperature      | K     | temperature derived from pressure and density |\n",
    "| time      | days     | time in days |\n",
    "| qrtend_MG2      | kg/kg/s     | qr tendency due to autoconversion & accretion in MG2 |\n",
    "| nrtend_MG2      | kg/kg/s     | nr tendency due to autoconversion & accretion in MG2 |\n",
    "| nctend_MG2      | kg/kg/s     | nc tendency due to autoconversion & accretion in MG2 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, and Test Datasets\n",
    "\n",
    "There are 176 files that will be split into training, validation, and test datsets via indices found in the `subset_data` variable defined below. In total, these files contain 85,263,948 data points and is randomly sampled using the `subsample` variable below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "import yaml\n",
    "from os.path import join, exists\n",
    "import os\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlmicrophysics.metrics import heidke_skill_score, peirce_skill_score, hellinger_distance, root_mean_squared_error, r2_corr\n",
    "from mlmicrophysics.models import DenseNeuralNetwork\n",
    "from mlmicrophysics.data import subset_data_files_by_date, assemble_data_files\n",
    "\n",
    "\n",
    "# set random seed\n",
    "seed = 328942\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define data parameters\n",
    "\n",
    "data_path = \"ncar-aiml-data-commons/microphysics\"\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    out_path = \"/content/gdrive/My Drive/micro_models/base\"\n",
    "else:\n",
    "    out_path = \"./micro_models/base/\"\n",
    "if not exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "subsample = 0.1\n",
    "input_cols = [\"QC_TAU_in\", \"NC_TAU_in\", \"QR_TAU_in\", \"NR_TAU_in\", \"RHO_CLUBB_lev\"]\n",
    "output_cols = [\"qrtend_TAU\", \"nctend_TAU\", \"nrtend_TAU\"]\n",
    "\n",
    "subset_data = {\"train_date_start\" : 0,\n",
    "               \"train_date_end\" : 11000,\n",
    "               \"test_date_start\" : 11100,\n",
    "               \"test_date_end\" : 17500}\n",
    "\n",
    "input_scaler = StandardScaler()\n",
    "input_transforms = {\"QC_TAU_in\" : \"log10_transform\",\n",
    "                    \"NC_TAU_in\" : \"log10_transform\",\n",
    "                    \"QR_TAU_in\" : \"log10_transform\",\n",
    "                    \"NR_TAU_in\" : \"log10_transform\"}\n",
    "\n",
    "output_transforms = {\"qrtend_TAU\" : {0: [\"<=\", 1e-18, \"zero_transform\", \"None\"],\n",
    "                                   1: [\">\", 1e-18, \"log10_transform\", \"RobustScaler\"]},\n",
    "                     \"nctend_TAU\" : {0: [\">=\", -1e-18, \"zero_transform\", \"None\"],\n",
    "                                   1: [\"<\", -1e-18, \"neg_log10_transform\", \"RobustScaler\"]},\n",
    "                     \"nrtend_TAU\" : {-1: [\"<\", 0, \"neg_log10_transform\", \"RobustScaler\"],\n",
    "                                   0: [\"==\", 0, \"zero_transform\", \"None\"],\n",
    "                                   1: [\">\", 0, \"log10_transform\", \"RobustScaler\"]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting file paths by train, validation, and test\n",
      "File times:\n",
      " [    0   100   200   300   400   500   600   700   800   900  1000  1100\n",
      "  1200  1300  1400  1500  1600  1700  1800  1900  2000  2100  2200  2300\n",
      "  2400  2500  2600  2700  2800  2900  3000  3100  3200  3300  3400  3500\n",
      "  3600  3700  3800  3900  4000  4100  4200  4300  4400  4500  4600  4700\n",
      "  4800  4900  5000  5100  5200  5300  5400  5500  5600  5700  5800  5900\n",
      "  6000  6100  6200  6300  6400  6500  6600  6700  6800  6900  7000  7100\n",
      "  7200  7300  7400  7500  7600  7700  7800  7900  8000  8100  8200  8300\n",
      "  8400  8500  8600  8700  8800  8900  9000  9100  9200  9300  9400  9500\n",
      "  9600  9700  9800  9900 10000 10100 10200 10300 10400 10500 10600 10700\n",
      " 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900\n",
      " 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100\n",
      " 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300\n",
      " 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500\n",
      " 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700\n",
      " 16800 16900 17000 17100 17200 17300 17400 17500]\n",
      "\n",
      "Loading training data\n",
      "Finished loading 0/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_000100.parquet\n",
      "Finished loading 10/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_001600.parquet\n",
      "Finished loading 20/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_003100.parquet\n",
      "Finished loading 30/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_004600.parquet\n",
      "Finished loading 40/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_006100.parquet\n",
      "Finished loading 50/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_007600.parquet\n",
      "Finished loading 60/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_009100.parquet\n",
      "Finished loading 70/74 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_010600.parquet\n",
      "Combining data\n",
      "Combined Data Size (3562915, 5)\n",
      "Transforming data\n",
      "\n",
      "Loading testing data\n",
      "Finished loading 0/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_011100.parquet\n",
      "Finished loading 10/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_012100.parquet\n",
      "Finished loading 20/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_013100.parquet\n",
      "Finished loading 30/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_014100.parquet\n",
      "Finished loading 40/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_015100.parquet\n",
      "Finished loading 50/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_016100.parquet\n",
      "Finished loading 60/65 files... opening file ncar-aiml-data-commons/microphysics/cam_mp_data_run5_017100.parquet\n",
      "Combining data\n",
      "Combined Data Size (3188152, 5)\n",
      "Transforming data\n"
     ]
    }
   ],
   "source": [
    "# Load data from disk or cloud\n",
    "# Separate input, output and meta data\n",
    "# Split into training, validation, and test sets\n",
    "\n",
    "print(\"Subsetting file paths by train, validation, and test\")\n",
    "train_files, val_files, test_files = subset_data_files_by_date(data_path, **subset_data)\n",
    "\n",
    "print(\"\\nLoading training data\")\n",
    "scaled_input_train, \\\n",
    "labels_train, \\\n",
    "transformed_out_train, \\\n",
    "scaled_out_train, \\\n",
    "output_scalers, \\\n",
    "meta_train = assemble_data_files(train_files, input_cols, output_cols, input_transforms,\n",
    "                                 output_transforms, input_scaler, subsample=subsample)\n",
    "\n",
    "print(\"\\nLoading testing data\")\n",
    "scaled_input_test, \\\n",
    "labels_test, \\\n",
    "transformed_out_test, \\\n",
    "scaled_out_test, \\\n",
    "output_scalers_test, \\\n",
    "meta_test = assemble_data_files(test_files, input_cols, output_cols, input_transforms,\n",
    "                                output_transforms, input_scaler, output_scalers=output_scalers,\n",
    "                                train=False, subsample=subsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qrtend_TAU_1</th>\n",
       "      <td>-11.404512</td>\n",
       "      <td>3.323476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nctend_TAU_1</th>\n",
       "      <td>-0.019442</td>\n",
       "      <td>4.235357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nrtend_TAU_-1</th>\n",
       "      <td>-3.100924</td>\n",
       "      <td>3.327674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nrtend_TAU_1</th>\n",
       "      <td>-1.998863</td>\n",
       "      <td>2.839761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  center     scale\n",
       "qrtend_TAU_1  -11.404512  3.323476\n",
       "nctend_TAU_1   -0.019442  4.235357\n",
       "nrtend_TAU_-1  -3.100924  3.327674\n",
       "nrtend_TAU_1   -1.998863  2.839761"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save meta data, input scalers, and output scalers\n",
    "    \n",
    "meta_test.to_csv(join(out_path, \"meta_test.csv\"), index_label=\"index\")\n",
    "\n",
    "input_scaler_df = pd.DataFrame({\"mean\": input_scaler.mean_, \"scale\": input_scaler.scale_},\n",
    "                               index=input_cols)\n",
    "input_scaler_df.to_csv(join(out_path, \"input_scale_values.csv\"), index_label=\"input\")\n",
    "\n",
    "out_scales_list = []\n",
    "for var in output_scalers.keys():\n",
    "    for out_class in output_scalers[var].keys():\n",
    "        if output_scalers[var][out_class] is not None:\n",
    "            out_scales_list.append(pd.DataFrame({\"center\": output_scalers[var][out_class].center_,\n",
    "                                                 \"scale\": output_scalers[var][out_class].scale_},\n",
    "                                                index=[var + \"_\" + str(out_class)]))\n",
    "out_scales_df = pd.concat(out_scales_list)\n",
    "out_scales_df.to_csv(join(out_path, \"output_scale_values.csv\"),\n",
    "                     index_label=\"output\")\n",
    "out_scales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAADSCAYAAAA7ShvPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7xldX3f+9ebUaRFHWMgRgcmQzJIiqS16blgTG3xUdFBmKBWDQMPxYY6Mbc06SNNryTNDSY27dRYb4hgcMR5jFgFqSHJoGMwsRcHG9oMpolhICQTgnIYdSDgJESviH7uH2sf2J45Z8/es3/v/Xo+HvOYs79777U/65z13d+1Puu7PitVhSRJkiRJkubHMeMOQJIkSZIkSaNlQkiSJEmSJGnOmBCSJEmSJEmaMyaEJEmSJEmS5owJIUmSJEmSpDljQkiSJEmSJGnOmBCSJEmSJEmaMyaENDRJPpHkknHHIamR5CVJ7hl3HJJWlmRfkrPHHYekRpKLk3xy3HFIOjpJbk3yL8cdxyQzITRhkrwpyZ8k+WqSLyV5T5K1bc8/P8l/S/JQkkNJPpfkp5OsWWV5L0nyaOvf3yaptsePJlnfet3bWs+duez9b0vyX1dYbiXZ2GldqurcqvrA0f0mpMmQ5L4kX05yfFvbv0xya+vnJPnJJHe2+thiq4/+QIdlfqKtD34jyWNtj69pveb41uPdK7z/sP63Wl9tV1W3VdVpPf4KpInWadxs9YtvtPrSV5L8fpIfOsLyLm7rj19L8q32cbPtdTuTPJ7kecvevzPJf1jWtqHVb5/S6bOr6gVVdWvPvwRpgnQxblZrvHw0yQNJ3rXafmzb+/e19cNvJvn/2h7/XOs1p7T663uWvXfF/rdSX12uqj5UVS/v8VcgDUWrb32ttd1/qbUNP731XFdjT5IXJ/nvSf6mdSx5c5LTu/z8Zyb51SRfaMWwv/X4hLb4XrbC+zrutyY5e9lY+0CSX1xhGUvfGw8luT7Js7r93Wl1JoQmSJJ/C/xn4N8Ba4EXARuATyZ5apLvA/4XcD/wA1W1FngdsAA8Y6Vltg4An15VTwde0Gp+1lJbVX0hSYA3AA8DzuiRDvcU4KdWee7K1nM/CTwbeD7wW8B5qy2slSxd6pcfAt7R1iff0nrZa4GvAy9P8twBrYc0U440brZe9pFWXzsB+H+B/9Zpma0DwKX+eS5woK1/Lu14Hw/8c+AQcPHg10yaep3GTYB/0OpP/xT4UeDHOi2slSxd6oO3AZe19cv/2HrZG4FHgAuTPK3/VZAm0uZWP3gh8A+Bn+32ja0TIp8Efht4HnAK8MfA/0jyvUd477HAp2iOJzcBzwReDPwVcGaHt3brQFsf/8fApUletew1S98b3wt8B/C2AXzu3DMhNCGSPBP4ReBfV9XvVNU3quo+4PU0nfWi1vO/X1U/XVVfBKiqe6rqoqr6Sh8f/xKaL4WfohlEj+1nXZakbYpe6wzuZ5K8M8kjSf4yybmD+BxpBH4F+JnlZyKSnAr8K2BLVf33qvp6VX21dUC5rc/PvAS4BvgcAzrgbJ2BWWx7fF+Sn0kz0/BQko8kOW4QnyUNW5fj5hOq6nGaBOy6JCf2+fH/HPgK8EsM8ERK+9nV1tnTG5Nc1zqTuy/JwqA+SxqyFcfN5apqP/A/aA5u+/VG4OeBbwCbB7C8J/Zf2x5Xkrck+fPW/uzVrROr0khV1ZeAW+it77wDuK6qrqyqv6mqh6vq54H/yZGTK28E1gOvrqq7qupbVXWwqt5eVYfNZu9HVf0l8PvAijOXquqvgV2rPd9Jkh9Lcner/96S5Hta7dckeeey1/52kp/ufQ2miwmhyfFi4DjgpvbGqnoU+ATwcuBlwEeH8NmXADcDH2k9Pn8InwFwFnAPzVnadwDvdxDVlLgDuBX4mWXt/wxYrKo/GOSHpbmU82yag9cP0QzCw/J6mjM9pwB/H3jTED9LGqRuxs0ntE52vJHmbOYjfX72JcD1wA3A9yf5wT6Xt5ofaX3Gs2h2fq8a0udIg7bauPltknw/zYnJ/f18WJKXACfR9JcbGe64eT7wfwD/gGYMfcUQP0taUZKTaGaxdtV3kvxdmnFzpVmyNwLnHGERLwN+pzXGDlXrhOsP0ySqVnr+O4BXrfZ8h+W+Cvg54DXAiTSzDa9vPf1h4EeXjk1bn/Fymu+UmWZCaHKcADzUOoO53BdpNtrvbP08MK0vh9cBH66qb9AknIZ12djnq+p9VfVN4APAc4HnDOmzpEH7BeBfL5tZMPA+2fJG4HNVdRfNQPWCJP9wCJ8D8GtVdaCqHqZJDA/iLK00Ct2MmwCvT/IV4GvAm4HXrvKerrQSti+lGTe/TDOFfljj5meqandr3PwgzQGoNC1WGjeX/GGSvwXupkkcvWeF1/TiEuATVfUIzYHduUm+q89lrmZbVX2lqr5Acxmq46ZG6beS/A1NCZGDwBVtz/1Mmnp5X2mNe59re+7ZNMf+K+23fpFmTO1kWPu8S57XivuvgT+jKZPymWWv+cPWej1EM1vpvT1+xo8D/6mq7m7tB/xH4IWtWUK3AUWToIamdMPtVXXg6FZnepgQmhwPASdk5YKTzwUepDmrOehaIq8GHgeWpvp9iGYQXRq8Hwee2v6GtroM3+jxs7609ENVfbX149N7XIY0FlV1J/Ax4PK25mH0SWgSQh9qfe4B4NN8+wHnN1nWL1uPe+2T0NYvga9in9T06GbcBLixqp5FcwLiTuAf9fm5bwDurqo/aj3+EHBR29h42LjZevyt1r9eLO+fx62yvtLEWWXcXPKDNOPNj9LMID9+hdd0JcnfoTm5uTRu3g58gScvG11KADtuaha8qqqeQTOT/Pv59kTOO6vqWUv/aGZ+L3mEZgxaab/1uTRjaif97PN2s996oBX3M2lmxX6NZgJBux9srddxwK8Dt/VY6uB7gCvbEmYPAwHWVVXRzAba0nrtRbS+U2adCaHJcTtNAdnXtDe2CleeS3NA+Hs0dQsG6RKagewLSb5EM43wqTzZGb5AU6Cz3Sk0HfuBAcciTboraGYYrGs9/hRw0iDreiR5MXAq8LNp7iDxJZqd5S1tB4Kr9cvPDyoOaQp0M24+oaoeojk7+LY+C7W/Efjetv75Lpod8qW6eKv1z/urqteEkDTtlo+bT6jGjTR9+Rf6+IxX0xS4fU9bv1zHk5eNfZHmwHPDsvc5bmpqVdWngZ3AO4/w0qXX/y1NX3vdCk+/nmaftpPfA16RtrsH9qCn/daqOkQz02/FWmCtq1qubS3jjB7iuB/48fakWVX9nar6/dbz1wOvbc0YOgv4jR6WPbVMCE2I1ob/i8C7k2xq3VVsA02C5iGaDOUVwIuT/EqS7wZIsjHJfz2a2+4lWUdTA+V8mumuL6SZjv6feXI2wu8ApyV5QyumZ9NMr/toP1PupWnUKn75EZo7ilFVf04zzf36VsHmY5Mcl+TCJCudEe3GJcDv0hTKW+qXZwB/lycPOD8C/HySk5Ic0ypCu5nh1BiTJlKX4+by9/wpTRHO/+toPjPNHVq+j+aOKu3988M8OW7+BnBekpcnWZPmtvQ/zxzUIZCWWz5urmIbsHVp3/YoXALsAH6AJ/vlD9NcCvIDrUsufwP45STf2fqu2EIzzn7iKD9TmgS/CpyTpNvLFi8HLknyk0mekeQ70tyq/odoxtNOPkiTUPmNJN/f2v/8ziQ/l+SVba97amtfeOnfU+hxvzXJ04ELgX2rPL8G+Bc0s4ju7XLdoblZy88meUFrOWuTPJEgq6r/TTO7+Frglj5v2jQ1TAhNkKp6B02hq3cCfwP8Jc1B4Muq6m+r6i9oOuwGYF+SQzQD3B2t1/fqDcAfVdUnq+pLS/+AXwP+fpIzquog8Eqas6oHaabbHwJ+oo9VlabZL/HtU9t/kqbQ69U0dx36C5qzlTf3uuDWtNfXA+9u75Otuy18kCcPOH+J5u4Ln6GZAvwO4OLW9Hxpbhxp3Fzlbb9Cc/B5NPVFLgF+u6r+ZNm4eSVwfpJnV9U+mlm2/4lmOvrtNLUQjrSzLc2q5ePmt6mqP6GZ0ffvel1w28nNX102bn6W5qTm0rj5f9L0x8/R7M9eBpzXqgMmTaWqehC4Dvi/u3z9Z2iKoL+GZubc52luXf+PWyc5O7336zSFpf+U5sTlXwN/QDND9n+1vXQ3TaJm6d/b6G6/9XlJHk3yaCuuZ3P4XXb/uPX8IzR9+9WtGphdqarfpJn4cEOrVtGdPHmydcn1rfX8cLfLnXZpLpfTJEryYzQ7kD/cKlwnSZJW4bgpSZLUPRNCEy7JG4BvVJVTzSVJOgLHTUmSpO54ydiEq6oPdrNTm+TipWl2y/6teO3loKzymY8mecmR3y3NtiT7Vukfy6fADvIzf26Vz7ROguZCD+PmyPtKkvUdxs31w/pcaVqMY78yyTWrfOY1w/pMaRJN6z6kx6P9cYaQJEmSJGkqJDkGeDvN3eXuqKrltyeX1CVnCEmSJEmSxibJjiQHk9y5rH1TknuS7M+Td3C9AFgHfANYHHWs0iyZiBlCJ5xwQm3YsGHcYUhj8dnPfvahqjpx3HGsxL6peTaJfTPJZmDzM57xjDc///nPH3c40lhMYt9c4ripedZP30zyT4BHgeuq6oxW2xrgz4BzaBI/e2nu4vgjwCNV9d4kH62q1x5p+fZNzbNOffMpow5mJRs2bOCOO+4YdxjSWCT5/LhjWG7poHPjxo32Tc2tSeybVXUzcPPCwsKb7ZuaV5PYN5e4T6t51k/frKo9STYsaz4T2F9V97aWfwPN7KD7gcdar/lmN8u3b2qedeqbXjIm6TBVdXNVbV27du24Q5EkSdJ8WkeT/Fmy2Gq7CXhFkncDe1Z7c5KtSe5IcseDDz443EilKTURM4QkSZIkSWqTFdqqqr4KXHqkN1fVdmA7wMLCwvjrpEgTyBlCkiRJkqRJswic3Pb4JOBALwtIsjnJ9kOHDg00MGlWmBCSJEmS+uBBpzQUe4FTk5yS5FjgQmBXLwuwDILUmQkhSZKmhAed0mTyoFPqT5LrgduB05IsJrm0qh4HLgNuAe4GbqyqfT0u13FT6mBqaghtuPzjR3zNfdvOG0EkktodqW/aL6XBab/L2Lhj0Wzxu1yaXdNwHFVVW1Zp3w3s7mO5jpv6NtPQH0ZpahJCkiRJkiR1K8lmYPPGjRvHHYpGoJtkj76dCSFJkqQZ5g6ypHnlDCGpMxNCkiRJkjRhvLRF0rCZEJLmRJJjgLcDzwTuqKoPjDkkSZIk9cEZgJ15yZjUmQkhaYol2QGcDxysqjPa2jcBVwJrgGurahtwAbAOeBhYHEO4kqQeODtAkvrjJWNSZyaEpOm2E7gKuG6pIcka4GrgHJrEz94ku4DTgNur6r1JPgp8avThSuqHZzpnyyDO7Ds7QJIkHS0TQtIUq6o9STYsaz4T2F9V9wIkuYFmdtD9wGOt13xztWUm2QpsBVi/fv2AI5bUD890SpPJZK00meybs8MTIMNhQkiaPetokj9LFoGzaC4he3eSlwB7VntzVW0HtgMsLCzUEOOUJGkmmKzV0fAAd/jsm1JnJoSk2ZMV2qqqvgpc2tUCPJsiSZJ01Ez2SJoGJoSk2bMInNz2+CTgQC8L8GyKJPXHg0FJkjTpjhl3AJIGbi9wapJTkhwLXAjs6mUBSTYn2X7o0KGhBChJkiQNm/u0UmcDTwglOSbJLyd5d5JLBr18SU9Kcj1wO3BaksUkl1bV48BlwC3A3cCNVbWvl+VW1c1VtXXt2rWDD1qSJEkaAfdppc66umQsyQ7gfOBgVZ3R1r6JplDtGuDaqtpGczejdcDDNJeuSBqSqtqySvtuYPeIw5EkzahuLoG7b9t5I4hEkiQNSrc1hHYCVwHXLTUkWQNcDZxDk/jZm2QXcBpwe1W9N8lHgU8NNGJJQ2dRaUlanfWBJEmaXUca52fpBEhXCaGq2pNkw7LmM4H9VXUvQJIbaGYH3Q881nrNNwcTpqRRsqi0NJlM1kqSpFnkyZbx6KeG0Dqa5M+SxVbbTcArkrwb2LPam5NsTXJHkjsefPDBPsKQJGk+WAtBkqTuWVRa6qyf285nhbaqqq8Clx7pzVW1HdgOsLCwUH3EIWnAnIUgTb95mu4sSdJKnPUuddZPQmgROLnt8UnAgf7CkTQJHDwlzSunrOtoeCJFkjSN+rlkbC9wapJTkhwLXAjs6mUBTuGTJEnStPNyTknSNOoqIZTkeuB24LQki0kurarHgcuAW4C7gRural8vH+7gKU0mk7WSJEmSNNu6vcvYllXadwO7BxqRpLHzkjFJs8pLwiRJGi3H3snVzyVjkiRJkiRJmkL9FJXumwX4JEntujmD5N2xJElSNzzelDoba0LIy1IkSb0yaSRJkrrh8abU2VgTQpImk2dTJE0jaxRIkiR1zxpCkg7jHQAlSZIkabY5Q0iSJEmSJPXM2bnTzaLSkiSNUZKzgbcD+4AbqurWsQY0odzhlCRJGiyLSkuSNGBJdgDnAwer6oy29k3AlcAa4Nqq2gYU8ChwHLA4hnAlST0wQS1pVnjJmKTDOHtP6ttO4CrguqWGJGuAq4FzaBI/e5PsAm6rqk8neQ7wLuDi0Yc7Xh5cSZIkjZ5FpSUdxqLSUn+qag/w8LLmM4H9VXVvVT0G3ABcUFXfaj3/CPC0EYYpSZKkOeYMIUmSRmMdcH/b40XgrCSvAV4BPItmVtGKkmwFtgKsX79+iGEOnjOAJEmDYu09aXAsKi1JGpk5TwxkhbaqqpuAm4705qraDmwHWFhYqAHHJknS2Fh7TxoPi0pLkjQai8DJbY9PAg70soBJPJEy50k+CZjMvilNmZ1Ye08aOS8ZkyRpNPYCpyY5BXgAuBC4qJcFjPpEiskeqTue5JT6U1V7kmxY1vxE7T2AJEu19+5qPW/tPalPJoQkSRqwJNcDZwMnJFkErqiq9ye5DLiFZur7jqraN64YTfZIkibc3Nbek0bFhJAkSQNWVVtWad8N7D7a5XpZiiRpjlh7b8g8OSQTQpIO40GnjoY7FcPnZSmSNFyOZRNlJmvvSZPEu4xJOowHnZIkSRqzqau9p/nQTeL4vm3njSCS/h0zzg+vqpurauvatWvHGYYkSVMhyeYk2w8dOjTuUCRJGphW7b3bgdOSLCa5tKoeB5Zq790N3Nhr7T3HTakzLxmTJGlKeKZTkjSLhlV7b57HTS9/VDdMCEnSnJulaa+SJElLLFEidTbWS8YkSZIkSRoGS5RInZkQkiRpSlgLQZIkSYPiJWOSpCPyOvTJMM+1ECRpEBzP5ouXjEmdmRCSpBnnzq8kSZpHnkiROhtrQsiMrSbZrBXaTXI28HZgH3BDVd061oAkSZIk9cyTfRqUsSaEzNhqXGblSzTJDuB84GBVndHWvgm4ElgDXFtV24ACHgWOAxbHEK6kPnkiRZKk7jluSp1ZVFqabjuBTe0NSdYAVwPnAqcDW5KcDtxWVecCbwV+ccRxShoA75YiSVL3HDelzqwhJE2xqtqTZMOy5jOB/VV1L0CSG4ALququ1vOPAE8bWZCSJEkjMCszwCVpVEwISbNnHXB/2+NF4KwkrwFeATwLuGq1NyfZCmwFWL9+/RDDlCRJkiSNiwkhafZkhbaqqpuAm4705qraDmwHWFhYqAHHJkmSJI2ENYSkzqwhJM2eReDktscnAQd6WUCSzUm2Hzp0aKCBSZIkSaNiDSGpM2cISbNnL3BqklOAB4ALgYt6WYB3AJQmk2c6JUmabdbC0iiZEJKmWJLrgbOBE5IsAldU1fuTXAbcQnPb+R1Vta/H5XrQKU0gk7WSZpEHwJJmTTffa/dtO28EkXQ21oSQB51Sf6pqyyrtu4HdfSzXg05JkiRJmmFjTQh50ClJ/fGsqiRJ0sqcgCB1ZlFpSYexqLQkad4lOTvJbUmuSXL2uOOR1DuLSkudWUNI0mGcvSdJmkVJdgDnAwer6oy29k3AlTS1966tqm1AAY8Cx9HcwVNHydmskjSZTAhJkiRpXuwErgKuW2pIsga4GjiHJvGzN8ku4Laq+nSS5wDvAi4efbjSaBwpaTcJxW8lDZ4JIUmH8XpraTLZNzXJpuGOKlW1J8mGZc1nAvur6l6AJDcAF1TVXa3nHwGeNrIgJUkaERNCkg7jJWOTwSn2Ws6+KQ3FOuD+tseLwFlJXgO8AngWzayiFSXZCmwFWL9+/RDDlCRpsEwISZIkaZ5lhbaqqpuAm4705qraDmwHWFhYqAHHJmmKTMNMSamdCSFJh/GyFEnSHFkETm57fBJwYEyxTB1ns2qSTeI+rX1Gk8SEkKaOX6LD52UpkqQ5shc4NckpwAPAhcBF4w1J0iC4Tyt1ZkJIksbAxKYkjV6S64GzgROSLAJXVNX7k1wG3EJz2/kdVbWvx+VO3CwESZKOxISQJEmS5kJVbVmlfTewu4/lOgtBkjR1TAhJOoxnOvvnDCBJkiRJk8yEkKTDeKZT0867fEiSJEmdHTPOD0+yOcn2Q4cOjTMMSZKmguOmJEmSBmWsCaGqurmqtq5du3acYUiSNBUcN6XJZLJWkjSNvGRMknpkfSBJUjsvtZYkTSMTQpLmhokcSdI4Wd9MGowkxwN7gCuq6mPjjkeaVmO9ZEzSZHLquyRJkkYlyY4kB5Pcuax9U5J7kuxPcnnbU28FbhxtlNLscYaQpMM49V2SJEkjtBO4CrhuqSHJGuBq4BxgEdibZBfwPOAu4LhRBuhMc80iE0KSJElSH5JsBjZv3Lhx3KEMlAfAGpWq2pNkw7LmM4H9VXUvQJIbgAuApwPHA6cDX0uyu6q+tXyZSbYCWwHWr18/vOClKeYlY5IkSVIfvAOgNBTrgPvbHi8C66rq31fVvwE+DLxvpWQQQFVtr6qFqlo48cQTRxCuNH2cISRJkiRJmjRZoa2e+KFq5xEXMKOz96RBMSEkSZIkSZo0i8DJbY9PAg70sgDrYmqSTcKdJ71kTJIkSZI0afYCpyY5JcmxwIXArl4W4J1zpc5MCEk6jIOnJEmSRiXJ9cDtwGlJFpNcWlWPA5cBtwB3AzdW1b5elmt9L6kzLxmTdBin10qS1D3rlEj9qaotq7TvBnaPOBxpbpgQ0kTx9qaS5lGS44E9wBVV9bFxxyOpN55IkSaTyVqpMy8ZkyRpwJLsSHIwyZ3L2jcluSfJ/iSXtz31VuDG0UYpSdJs85IxqTMTQpIkDd5OYFN7Q5I1wNXAucDpwJYkpyd5GXAX8OVRBylJ0iyzLqbUmQkhSZIGrKr2AA8vaz4T2F9V91bVY8ANwAXAS4EXARcBb07i2CxJ0gA4Q0jqzBpCkiSNxjrg/rbHi8BZVXUZQJI3AQ9V1bdWenOSrcBWgPXr1w83UkmSJM08z0JKkjQaWaGtnvihamengtJVtb2qFqpq4cQTTxxKgJIkSZofJoQkSRqNReDktscnAQfGFIukAbJOiTSZ7JtSZwNPCCU5O8ltSa5Jcvagly9J0pTaC5ya5JQkxwIXArt6WYA7ttJksk6JNJnsm1JnXSWEerx9bgGPAsfRnA2VNCGSHJ/ks0nOH3cs0ixLcj1wO3BaksUkl1bV48BlwC3A3cCNVbWvl+W6YytJkqRB6bao9E7gKuC6pYa22+eeQ5P42ZtkF3BbVX06yXOAdwEXDzRiaYJsuPzjR3zNfdvOG9rnJ9kBnA8crKoz2to3AVcCa4Brq2pb66m3AjcOLSBJAFTVllXadwO7j3a5STYDmzdu3Hi0i5AkSct0s08vzaKuZgj1cvvctrujPAI8bbVlJtma5I4kdzz44INHEbokmmTtpvaGtmTtucDpwJYkpyd5GXAX8OVRBylpMJwhJElS97zUWuqsnxpCK90+d12S1yR5L/BBmllFK/JuKVL/eknWAi8FXgRcBLw5iUXlJUmSNLM8kSJ11u0lYytZ8fa5VXUTcFMfy5XUn5WStWdV1WUASd4EPNQ2m+/bJNkKbAVYv379cCOVJEmSJI1FPzMEvH2uNJlWTNY+8UPVzqr62GpvdvaeNLmc+i5JkqRB6WeG0BO3zwUeoLl97kW9LMDimPPFYm0j03ey1r4pTaaquhm4eWFh4c3jjkWSJEnTrdvbznv7XGl6PJGsTXIsTbJ2Vy8LsG9KktQ9Z+9Jk8m+KXXW7V3GtlTVc6vqqVV1UlW9v9W+u6qeX1XfV1W/PNxQJS03rGStg6c0meyb0mTyRIo0meybUmfeZUiaYsNK1jp4SpPJvilJkqRBGWtCyDOd0mSyb0qSJEnSbBtrQsgzndJksm9KkiRJ0mzzkjFJkiRJkqQ5Y0JI0mG8ZEyaTPZNSZIkDYo1hCQdxkvGpMlk35QkqXseb0qdPWWcH15VNwM3LywsvHmccUgang2Xf/yIr7lv23kjiESSJEnzxONNqbOxJoQ0W7o58JckSZIkSeNnDSFJh3F6rSRJkiTNNhNCkg5jnRJpMpmslSaTfVOSNI0sKi1J0pQwWStNJvumJGkajTUh5OApSZIkSZI0ehaVlnSYJJuBzRs3bhx3KD2xsLkkSZIkdccaQpIO4+w9SZIkTaIkfy/JNUk+muQnxh2PNM2cIaSuOPNCkiRJ0jAk2QGcDxysqjPa2jcBVwJrgGuraltV3Q28JckxwPvGErA0I5whJEmSJEkap53ApvaGJGuAq4FzgdOBLUlObz33I8BngE+NNkxptniXMUmSpoTjpiRpFlXVHuDhZc1nAvur6t6qegy4Abig9fpdVfVi4OLRRirNFu8yJukwHnRKk8lxU5I0R9YB97c9XgTWJTk7ya8leS+we7U3J9ma5I4kdzz44IPDjlWaStYQknSYqroZuHlhYeHN445FkiQNnvUhNQWyQltV1a3ArUd6c1VtB7YDLCws1EAjk2aENYQkSZIkSZNmETi57fFJwIFeFuCsd6kzZwjJM0SSJEmSJs1e4NQkpwAPABcCF/WyAGe9S505Q0iSJEmSNDZJrgduB05Lspjk0qp6HLgMuAW4G7ixqvb1uFxnCEkdOENIkiRJkjQ2VbVllfbddCgc3cVynSEkdeAMIUmSJEnSzHGGkNTZWBNCdlBJkiRJ0jBU1c1VtXXt2rXjDkWaSGO9ZBzV/bYAAArYSURBVMwpfMNnwWgdjSSbgc0bN24cdyiSJE08x01J0jTykjFJh/FsijSZnFkrTSbHTWkyOW5KnVlUWtLYdTOT7b5t540gEmmyObNWkqTuOW5KnTlDSJIkSZIkac6YEJIkSZIkzRwvGZM685KxKWfRaEmSJEk6nJeMSZ05Q0iSJEmSJGnOmBCSJEmSJEmaMyaEJEmSJEkzxxpCUmdjrSGUZDOweePGjeMMY2JZH0iSJEmSjo41hKTOxpoQsoNKo5Pk7wE/BZwAfKqqfn3MIUmSpGW6OSF437bzRhCJJGnWecmYNMWS7EhyMMmdy9o3Jbknyf4klwNU1d1V9Rbg9cDCOOKVJEmSJE0GE0LSdNsJbGpvSLIGuBo4Fzgd2JLk9NZzPwJ8BvjUaMOUJEmSJE2SsV4yNs+sD6RBqKo9STYsaz4T2F9V9wIkuQG4ALirqnYBu5J8HPjwSstMshXYCrB+/fohRS5JkiQNlzVrpc5MCEmzZx1wf9vjReCsJGcDrwGeBuxe7c1VtR3YDrCwsFDDC1MSWN9L0nB48lGyZq10JCaEpNmTFdqqqm4Fbu1qAZ5NkfqSZAdwPnCwqs5oa98EXAmsAa6tqm1VdTfwliTHAO8bS8CSJEmaOyaEhsSzMhqjReDktscnAQd6WYBnU6S+7QSuAq5bamir73UOTT/dm2RXVd3Vqu91ees9kiRJ0tBZVFqaPXuBU5OckuRY4EJgVy8LSLI5yfZDhw4NJUBp1lXVHuDhZc1P1PeqqseApfpeVNWuqnoxcPFqy0yyNckdSe548MEHhxW6JEmS5oQzhI6Cs380KZJcD5wNnJBkEbiiqt6f5DLgFprLUnZU1b5elusMIWkorO8lSZKkiWFCSJpiVbVllfbddDiwlDQWfdf3kiRJkgbFhNAyzv6RLCotDUnf9b3sm5Ikdc9xU+rMGkKSDlNVN1fV1rVr1447FGmW9F3fy74pSVL3HDelzsY6Q2jUGVtn/0iSRmFY9b080ylJkqRBGWtCaNCFa034SIMxiQed9m9Nk2HV97Lgu6bdkb7L79t23ogimW6OiZI0H4Y9bnrJmKTDOL1WkiRIcnySzyY5f9yxSJI0aCaEJEmSNBeS7EhyMMmdy9o3Jbknyf4kl7c99VbgxtFGKUnSaJgQknSYJJuTbD906NC4Q5HUxr4p9W0nsKm9Icka4GrgXOB0YEuS05O8DLgL+PKog5QkaRRMCEk6jJeMSZPJvin1p6r2AA8vaz4T2F9V91bVY8ANwAXAS4EXARcBb07ifrMkaaaMtai0JEmSNGbrgPvbHi8CZ1XVZQBJ3gQ8VFXfWunNSbYCWwHWr18/3EglSRogz3RIkjQlvGRMGoqs0FZP/FC1s6o+ttqbq2p7VS1U1cKJJ544lAAlSRoGE0KSJE0JLxmThmIROLnt8UnAgTHFIknSyKSqjvyqYQeRPAh8ftxx9OAE4KFxBzEiruvwfU9VTdQpxSSbgc3AjwJ/PuSPm5ZtzDgHaxriPK2qnjHuIFYyRePmNPyd+zXr6ziJ69fXuJlkA/Cxqjqj9fgpwJ8B/wx4ANgLXFRV+45i2ePom5P4N+qH6zPZOq3PxO3TLpmicXMls7YN9cr173/9V+2bE5EQmjZJ7qiqhXHHMQquq4ZtWn7vxjlY0xDnNMQ46ebhdzjr6zhr65fkeuBsmh3sLwNXVNX7k7wS+FVgDbCjqn55fFH2Zgb/Rq7PBJu19ZkG8/47d/2Hu/4WlZYkSdJcqKotq7TvBnaPOBxJksbKGkKSJEmSJElzxoTQ0dk+7gBGyHXVsE3L7904B2sa4pyGGCfdPPwOZ30dZ339ZsGs/Y1cn8k2a+szDeb9d+76D5E1hCRJkiRJkuaMM4QkSZIkSZLmjAmhHiR5XZJ9Sb6VZKGtfUOSryX5o9a/a8YZ5yCstq6t5342yf4k9yR5xbhiHIYkb0vyQNvf8pXjjmlWTeM2NsnbR5JNrd/X/iSXjzue1SS5L8mftH5/d4w7niVJdiQ5mOTOtrZnJ/ndJH/e+v87xhnjNJn18XIav7/6McnfffNslrfDWdjmpmVc7takjt+z5EjbTJKzkxxq6xe/MI44h2Gl/bBlzyfJr7V+N59L8oOjjnGYulj/of3tvctYb+4EXgO8d4Xn/qKqXjjieIZpxXVNcjpwIfAC4HnA7yV5flV9c/QhDs3/U1XvHHcQc2Bat7GJ2z6SrAGuBs4BFoG9SXZV1V3jjWxVL62qh8YdxDI7gauA69raLgc+VVXbWjtmlwNvHUNs02jWx8tp/f7qx8R992nmt8Op3eamcFzu1iSO3zOhh23mtqo6f+QBDt9ODt8Pa3cucGrr31nAr7f+nxU76bz+MKS/vTOEelBVd1fVPeOOYxQ6rOsFwA1V9fWq+ktgP3DmaKPTLHAbG6gzgf1VdW9VPQbcQPN7VJeqag/w8LLmC4APtH7+APCqkQY1xWZ9vPT7S5PA7XCiOS6rV3O9zayyH9buAuC6avxP4FlJnjua6Iavi/UfGhNCg3NKkv+d5NNJXjLuYIZoHXB/2+PFVtssuaw1FXGHl4iMxaRvY5O4fUz676xdAZ9M8tkkW8cdzBE8p6q+CND6/7vGHM+smOXxcpr6Yq8m8btPK5uV7XCat7lZ+Ru0m6bxexp1u838UJI/TvKJJC8YTWgTYRb7VK+G8rf3krFlkvwe8N0rPPXvq+q3V3nbF4H1VfVXSf4R8FtJXlBVfz20QAfgKNc1K7RN1a3qOq03zfTDt9Os09uB/wL82Oiimy3TuI1N6fYxTf3yh6vqQJLvAn43yZ+2zopoysz6eDmN31/9mNLvvpk3y9vhjG9zU/E36JHj93B1s838IfA9VfVoq67Wb9FcQjUPZrFP9WJof3sTQstU1cuO4j1fB77e+vmzSf4CeD4w0QXXjmZdabKxJ7c9Pgk4MJiIRqPb9U7yPuBjQw5npk3jNjal28fU9MuqOtD6/2CS36SZIj2pO5RfTvLcqvpia1rywXEHNElmfbycxu+vfkzpd9/Mm+XtcMa3uan4G/RiysbvaXTEbab95ElV7U7yniQnzEldp5nrU70Y5t/eS8YGIMmJrUJgJPlemmzdveONamh2ARcmeVqSU2jW9Q/GHNPALLsW9dU0BRs1WhO7jU3w9rEXODXJKUmOpSkmumvMMR0myfFJnrH0M/ByJud3uJJdwCWtny8BVjsbry7NwXg5sd9f/Zjg7z6tbOq3wxnY5qZiXO7WFI7f0+iI20yS706S1s9n0hzL/9XIIx2PXcAb03gRcGjpsv55MMy/vTOEepDk1cC7gROBjyf5o6p6BfBPgF9K8jjwTeAtVTWWolCDstq6VtW+JDcCdwGPA/9qCu9a0ck7kryQZgrifcCPjzec2TWl29hEbh9V9XiSy4BbgDXAjqraN+awVvIc4Ddb49lTgA9X1e+MN6RGkuuBs4ETkiwCVwDbgBuTXAp8AXjd+CKcLrM+Xk7p91c/JvK7b97N+HY41dvcFI3L3ZrY8XtWrLbNJHlL6/lrgNcCP9EaQ78GXFhVM3HZ1Cr7YU+FJ9Z9N/BKmiL5XwX+xXgiHY4u1n9of/vMyDYkSZIkSZKkLnnJmCRJkiRJ0pwxISRJkiRJkjRnTAhJkiRJkiTNGRNCkiRJkiRJc8aEkCRJkiRJ0pwxISRJkiRJkjRnTAhJkiRJkiTNGRNCkiRJkiRJc+b/B69WbCkl0Ua1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograms of original training input data by column\n",
    "\n",
    "fig, axes = plt.subplots(1,5, figsize=(20, 3))\n",
    "transformed_input_train = pd.DataFrame(input_scaler.inverse_transform(scaled_input_train), columns=input_cols)\n",
    "for a, ax in enumerate(axes.ravel()):\n",
    "    if a < len(input_cols):\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.hist(transformed_input_train[input_cols[a]], bins=20)\n",
    "        ax.set_title(input_cols[a])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by RobustScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b12d6e9bac54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         scaled_out_train.loc[labels_train[output_col] == 1, [output_col]]).ravel()\n\u001b[1;32m      8\u001b[0m     original_out_train_nc[labels_train[output_col] == -1] = -10 ** output_scalers[output_col][1].inverse_transform(\n\u001b[0;32m----> 9\u001b[0;31m         scaled_out_train.loc[labels_train[output_col] == -1, [output_col]]).ravel()\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moriginal_out_train_nc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moriginal_out_train_nc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m   1274\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    652\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 654\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by RobustScaler."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output visualizations\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n",
    "for output_col, ax in zip(output_cols, (ax1, ax2, ax3)):\n",
    "    original_out_train_nc = np.zeros(scaled_out_train.shape[0])\n",
    "    original_out_train_nc[labels_train[output_col] == 1] = -10 ** output_scalers[output_col][1].inverse_transform(\n",
    "        scaled_out_train.loc[labels_train[output_col] == 1, [output_col]]).ravel()\n",
    "    original_out_train_nc[labels_train[output_col] == -1] = -10 ** output_scalers[output_col][1].inverse_transform(\n",
    "        scaled_out_train.loc[labels_train[output_col] == -1, [output_col]]).ravel()\n",
    "    ax.hist(np.log10(-original_out_train_nc[original_out_train_nc < 0]), bins=50)\n",
    "    ax.set_xlabel(output_col)\n",
    "    ax.set_ylabel('log10')\n",
    "    ax.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "    ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform and scaling of scaled train data\n",
    "\n",
    "original_out_train_nr = np.zeros(scaled_out_train.shape[0])\n",
    "original_out_train_nr[labels_train[\"nrtend_TAU\"] == 1] = 10 ** output_scalers[\"nrtend_TAU\"][1].inverse_transform(\n",
    "    scaled_out_train.loc[labels_train[\"nrtend_TAU\"] == 1, [\"nrtend_TAU\"]]).ravel()\n",
    "original_out_train_nr[labels_train[\"nrtend_TAU\"] == -1] = -10 ** output_scalers[output_col][1].inverse_transform(\n",
    "    scaled_out_train.loc[labels_train[\"nrtend_TAU\"] == -1, [\"nrtend_TAU\"]]).ravel()\n",
    "\n",
    "\n",
    "original_out_train_nc = np.zeros(scaled_out_train.shape[0])\n",
    "original_out_train_nc[labels_train[\"nctend_TAU\"] == 1] = -10 ** output_scalers[output_col][1].inverse_transform(\n",
    "    scaled_out_train.loc[labels_train[\"nctend_TAU\"] == 1, [\"nctend_TAU\"]]).ravel()\n",
    "\n",
    "original_out_train_qr = np.zeros(scaled_out_train.shape[0])\n",
    "original_out_train_qr[labels_train[\"qrtend_TAU\"] == 1] = 10 ** output_scalers[output_col][1].inverse_transform(\n",
    "    scaled_out_train.loc[labels_train[\"qrtend_TAU\"] == 1, [\"qrtend_TAU\"]]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output visualizations\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n",
    "\n",
    "output_col = \"nrtend_TAU\"\n",
    "ax1.hist(np.log10(-original_out_train_nr[original_out_train_nr < 0]), bins=50, label=\"<0\")\n",
    "ax1.hist(np.log10(original_out_train_nr[original_out_train_nr > 0]), bins=50, label=\">0\")\n",
    "ax1.set_xlabel(output_col)\n",
    "ax1.set_ylabel('log10')\n",
    "ax1.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "\n",
    "output_col = \"nctend_TAU\"\n",
    "ax2.hist(np.log10(-original_out_train_nc[original_out_train_nc < 0]), bins=50)\n",
    "ax2.set_xlabel(output_col)\n",
    "ax2.set_ylabel('log10')\n",
    "ax2.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "output_col = \"qrtend_TAU\"\n",
    "ax3.hist(np.log10(original_out_train_qr[original_out_train_qr > 0]), bins=50)\n",
    "ax3.set_xlabel(output_col)\n",
    "ax3.set_ylabel('log10')\n",
    "ax3.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and view a single file\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "filenames = fs.ls(\"s3://ncar-aiml-data-commons/microphysics\")\n",
    "fobj = fs.open(filenames[0])\n",
    "single_file = pd.read_parquet(fobj).set_index('Index')\n",
    "single_file.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Machine Learning Model\n",
    "Description of baseline ML approach should include:\n",
    "* Choice of ML software\n",
    "* Type of ML model\n",
    "* Hyperparameter choices and justification\n",
    "\n",
    "A baseline model for solving this problem uses an in-series classifier to regressor neural network architecture implemented in Keras.  Initially, there are three classifier networks that feed into four regressor networks. Each classifier and regressor network has 4 hidden layers of 30 neurons each and relu activation. Those hidden layers then feed into a final output layer of size 2 or 3 for classification (1 and 0 or 1, 0, and -1) and of size 1 for regression. The classifier models are trained using the categorial crosstenropy loss function while the regression models are trained using the mean squared error loss function.\n",
    "\n",
    "<center><img src='micro_images/mlmicrophysics_nn.png'><center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model hyper parameters\n",
    "\n",
    "classifier_metrics = [\"acc\", \"pss\", \"hss\"]\n",
    "regressor_metrics = [\"mse\", \"mae\", \"r2\", \"hellinger\"]\n",
    "\n",
    "classifier_networks = {\"hidden_layers\" : 4,\n",
    "                       \"hidden_neurons\" : 30,\n",
    "                       \"loss\" : \"categorical_crossentropy\",\n",
    "                       \"output_activation\" : \"softmax\",\n",
    "                       \"activation\" : \"relu\",\n",
    "                       \"epochs\" : 15,\n",
    "                       \"batch_size\" : 1024,\n",
    "                       \"verbose\" : 1,\n",
    "                       \"lr\" : 0.0001,\n",
    "                       \"l2_weight\" : 1.0e-5,\n",
    "                       \"classifier\" : 1}\n",
    "\n",
    "regressor_networks = {\"hidden_layers\" : 4,\n",
    "                      \"hidden_neurons\" : 30,\n",
    "                      \"loss\" : \"mse\",\n",
    "                      \"output_activation\" : \"linear\",\n",
    "                      \"activation\" : \"relu\",\n",
    "                      \"epochs\" : 15,\n",
    "                      \"batch_size\" : 1024,\n",
    "                      \"verbose\" : 1,\n",
    "                      \"lr\" : 0.0001,\n",
    "                      \"l2_weight\" : 1.0e-5,\n",
    "                      \"classifier\" : 0}\n",
    "\n",
    "# hyperparameter dictionaries\n",
    "class_metrics = {\"accuracy\": accuracy_score,\n",
    "                 \"heidke\": heidke_skill_score,\n",
    "                 \"peirce\": peirce_skill_score}\n",
    "\n",
    "reg_metrics = {\"rmse\": root_mean_squared_error,\n",
    "               \"mae\": mean_absolute_error,\n",
    "               \"r2\": r2_corr,\n",
    "               \"hellinger\": hellinger_distance}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and fit the model\n",
    "\n",
    "histories = {\"classifiers\": {}, \"regressors\": {}}\n",
    "classifiers = dict()\n",
    "regressors = dict()\n",
    "reg_index = []\n",
    "for output_col in output_cols:\n",
    "    for label in list(output_transforms[output_col].keys()):\n",
    "        if label != 0:\n",
    "            reg_index.append(output_col + f\"_{label:d}\")\n",
    "test_prediction_values = np.zeros((scaled_out_test.shape[0], len(reg_index)))\n",
    "test_prediction_labels = np.zeros(scaled_out_test.shape)\n",
    "classifier_scores = pd.DataFrame(0, index=output_cols, columns=[\"accuracy\", \"heidke\", \"peirce\"])\n",
    "confusion_matrices = dict()\n",
    "reg_cols = [\"rmse\", \"mae\", \"r2\", \"hellinger\"]\n",
    "reg_scores = pd.DataFrame(0, index=reg_index, columns=reg_cols)\n",
    "l = 0\n",
    "\n",
    "for o, output_col in enumerate(output_cols):\n",
    "    print(\"Train Classifer \", output_col)\n",
    "    classifiers[output_col] = DenseNeuralNetwork(**classifier_networks)\n",
    "    hist = classifiers[output_col].fit(scaled_input_train,\n",
    "                                       labels_train[output_col],\n",
    "                                       scaled_input_test,\n",
    "                                       labels_test[output_col])\n",
    "    histories[\"classifiers\"][output_col] = hist\n",
    "    classifiers[output_col].save_fortran_model(join(out_path,\n",
    "                                                    \"dnn_{0}_class_fortran.nc\".format(output_col[0:2])))\n",
    "    classifiers[output_col].model.save(join(out_path,\"dnn_{0}_class.h5\".format(output_col[0:2])))\n",
    "    regressors[output_col] = dict()\n",
    "    histories[\"regressors\"][output_col] = dict()\n",
    "    print(\"Evaluate Classifier\", output_col)\n",
    "    test_prediction_labels[:, o] = classifiers[output_col].predict(scaled_input_test)\n",
    "    confusion_matrices[output_col] = confusion_matrix(labels_test[output_col],\n",
    "                                                      test_prediction_labels  [:, o])\n",
    "    for class_score in classifier_scores.columns:\n",
    "        classifier_scores.loc[output_col, class_score] = class_metrics[class_score](labels_test[output_col],\n",
    "                                                                                    test_prediction_labels[:, o])\n",
    "    print(classifier_scores.loc[output_col])\n",
    "    for label in list(output_transforms[output_col].keys()):\n",
    "        if label != 0:\n",
    "            print(\"Train Regressor \", output_col, label)\n",
    "            regressors[output_col][label] = DenseNeuralNetwork(**regressor_networks)\n",
    "            hist = regressors[output_col][label].fit(scaled_input_train.loc[labels_train[output_col] == label],\n",
    "                                                     scaled_out_train.loc[labels_train[output_col] == label, output_col],\n",
    "                                                     scaled_input_test.loc[labels_test[output_col] == label],\n",
    "                                                     scaled_out_test.loc[labels_test[output_col] == label, output_col])\n",
    "            histories[\"regressors\"][output_col][label] = hist\n",
    "\n",
    "            if label > 0:\n",
    "                out_label = \"pos\"\n",
    "            else:\n",
    "                out_label = \"neg\"\n",
    "            regressors[output_col][label].save_fortran_model(join(out_path,\n",
    "                                                                  \"dnn_{0}_{1}_fortran.nc\".format(output_col[0:2],\n",
    "                                                                                                  out_label)))\n",
    "            regressors[output_col][label].model.save(join(out_path,\n",
    "                                                          \"dnn_{0}_{1}.h5\".format(output_col[0:2], out_label)))\n",
    "            print(\"Test Regressor\", output_col, label)\n",
    "            test_prediction_values[:, l] = output_scalers[output_col][label].inverse_transform(regressors[output_col][label].predict(scaled_input_test))\n",
    "            reg_label = output_col + f\"_{label:d}\"\n",
    "            for reg_col in reg_cols:\n",
    "                reg_scores.loc[reg_label,\n",
    "                               reg_col] = reg_metrics[reg_col](transformed_out_test.loc[labels_test[output_col] == label,\n",
    "                                                                                        output_col],\n",
    "                                                                test_prediction_values[labels_test[output_col] == label, l])\n",
    "            print(reg_scores.loc[reg_label])\n",
    "            l += 1\n",
    "print(\"Saving data\")\n",
    "classifier_scores.to_csv(join(out_path, \"dnn_classifier_scores.csv\"), index_label=\"Output\")\n",
    "reg_scores.to_csv(join(out_path, \"dnn_regressor_scores.csv\"), index_label=\"Output\")\n",
    "test_pred_values_df = pd.DataFrame(test_prediction_values, columns=reg_index)\n",
    "test_pred_labels_df = pd.DataFrame(test_prediction_labels, columns=output_cols)\n",
    "test_pred_values_df.to_csv(join(out_path, \"test_prediction_values.csv\"), index_label=\"index\")\n",
    "test_pred_labels_df.to_csv(join(out_path, \"test_prediction_labels.csv\"), index_label=\"index\")\n",
    "labels_test.to_csv(join(out_path, \"test_cam_labels.csv\"), index_label=\"index\")\n",
    "transformed_out_test.to_csv(join(out_path, \"test_cam_values.csv\"), index_label=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classifier model performance\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for k in histories['classifiers'].keys():\n",
    "    plt.plot(histories['classifiers'][k]['loss'], label=f\"{k} loss\")\n",
    "    plt.plot(histories['classifiers'][k]['val_loss'], label=f\"{k} val_loss\")\n",
    "plt.title('Classifier model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize regressor model performance\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for k in histories['regressors'].keys():\n",
    "    for l in histories['regressors'][k].keys():\n",
    "        plt.plot(histories['regressors'][k][l]['loss'], label=f\"{k} label {l} loss\")\n",
    "        plt.plot(histories['regressors'][k][l]['val_loss'], label=f\"{k} label {l} val_loss\")\n",
    "plt.title('regressor model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Prediction metrics by output variable for classifier networks:\n",
    "\n",
    "| Variable Name | accuracy | heidke | peirce |\n",
    "| ------------- |:----------- |:----------- |:----------- |\n",
    "| qrtend_TAU  |  0.98     | 0.97 | 0.99 | \n",
    "| nctend_TAU  |  0.99     | 0.99 | 0.97 |\n",
    "| nrtend_TAU  |  0.98     | 0.97 | 0.99 |\n",
    "\n",
    "Prediction metrics by output variable for regression networks:\n",
    "\n",
    "| Variable Name | rmse | mae | r2 | hellinger |\n",
    "| ------------- |:----------- |:----------- |:----------- |:----------- |\n",
    "| qrtend_TAU_1  |  0.20     | 0.10 | 0.99 | 0.00056 |\n",
    "| nctend_TAU_1  |  0.17     | 0.08 | 1.00 | 0.00099 |\n",
    "| nrtend_TAU_-1  |  0.20     | 0.11 | 0.99 | 0.00056 |\n",
    "| nrtend_TAU_1 | 0.25 | 0.16 | 0.98 | 0.00018 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscaled predicted output values\n",
    "\n",
    "pred_tendencies = pd.DataFrame(0, index=scaled_out_test.index, columns=output_cols, dtype=float)\n",
    "\n",
    "nr_pred_values = np.zeros(scaled_input_test.shape[0])\n",
    "nr_pred_values[test_pred_labels_df[\"nrtend_TAU\"] == 1] = (10 ** test_pred_values_df.loc[test_pred_labels_df[\"nrtend_TAU\"] == 1, [\"nrtend_TAU_1\"]]).values.flatten()\n",
    "nr_pred_values[test_pred_labels_df[\"nrtend_TAU\"] == -1] = (-10 ** test_pred_values_df.loc[test_pred_labels_df[\"nrtend_TAU\"] == -1, [\"nrtend_TAU_-1\"]]).values.flatten()\n",
    "pred_tendencies.loc[:, \"nrtend_TAU\"] = nr_pred_values\n",
    "\n",
    "pred_tendencies.loc[test_pred_labels_df[\"nctend_TAU\"] == 1, \"nctend_TAU\"] = (-10 ** test_pred_values_df.loc[test_pred_labels_df[\"nctend_TAU\"] == 1, [\"nctend_TAU_1\"]]).values.flatten()\n",
    "\n",
    "pred_tendencies.loc[test_pred_labels_df[\"qrtend_TAU\"] == 1, \"qrtend_TAU\"] = (10 ** test_pred_values_df.loc[test_pred_labels_df[\"qrtend_TAU\"] == 1, [\"qrtend_TAU_1\"]]).values.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscaled actual output values\n",
    "\n",
    "unscaled_tendencies = pd.DataFrame(0, index=scaled_out_test.index, columns=output_cols, dtype=float)\n",
    "\n",
    "nr_values = np.zeros(scaled_input_test.shape[0])\n",
    "nr_values[labels_test[\"nrtend_TAU\"] == 1] = (10 ** output_scalers[\"nrtend_TAU\"][1].inverse_transform(\n",
    "    scaled_out_test.loc[labels_test[\"nrtend_TAU\"] == 1, [\"nrtend_TAU\"]])).flatten()\n",
    "nr_values[labels_test[\"nrtend_TAU\"] == -1] = (-10 ** output_scalers[\"nrtend_TAU\"][-1].inverse_transform(\n",
    "    scaled_out_test.loc[labels_test[\"nrtend_TAU\"] == -1, [\"nrtend_TAU\"]])).flatten()\n",
    "unscaled_tendencies.loc[:, \"nrtend_TAU\"] = nr_values\n",
    "\n",
    "unscaled_tendencies.loc[labels_test[\"nctend_TAU\"] == 1, \"nctend_TAU\"] = (-10 ** output_scalers[\"nctend_TAU\"][1].inverse_transform(\n",
    "    scaled_out_test.loc[labels_test[\"nctend_TAU\"] == 1, [\"nctend_TAU\"]])).ravel()\n",
    "\n",
    "unscaled_tendencies.loc[labels_test[\"qrtend_TAU\"] == 1, \"qrtend_TAU\"] = (10 ** output_scalers[\"qrtend_TAU\"][1].inverse_transform(\n",
    "    scaled_out_test.loc[labels_test[\"qrtend_TAU\"] == 1, [\"qrtend_TAU\"]])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output visualizations\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16,4))\n",
    "\n",
    "output_col = \"nrtend_TAU\"\n",
    "colp = unscaled_tendencies[output_col]\n",
    "col = pred_tendencies[output_col]\n",
    "ax1.hist(np.log10(-colp[colp < 0]), label=\"<0 pred\", color='skyblue')\n",
    "ax1.hist(np.log10(colp[colp > 0]), label=\">0 pred\", color='pink')\n",
    "ax1.hist(np.log10(-col[col < 0]), label=\"<0 true\", histtype=\"step\", color=\"navy\", lw=3)\n",
    "ax1.hist(np.log10(col[col > 0]), label=\">0 true\", histtype=\"step\", color=\"purple\", lw=3)\n",
    "ax1.set_xlabel(output_col)\n",
    "ax1.set_ylabel('log10')\n",
    "ax1.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "\n",
    "output_col = \"nctend_TAU\"\n",
    "colp = unscaled_tendencies[output_col]\n",
    "col = pred_tendencies[output_col]\n",
    "ax2.hist(np.log10(-colp[colp < 0]), label=\"pred\", color='skyblue')\n",
    "ax2.hist(np.log10(-col[col < 0]), label=\"true\", histtype=\"step\", color=\"navy\", lw=3)\n",
    "ax2.set_xlabel(output_col)\n",
    "ax2.set_ylabel('log10')\n",
    "ax2.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "output_col = \"qrtend_TAU\"\n",
    "colp = unscaled_tendencies[output_col]\n",
    "col = pred_tendencies[output_col]\n",
    "ax3.hist(np.log10(colp[colp > 0]), label=\"pred\", color='skyblue')\n",
    "ax3.hist(np.log10(col[col > 0]), label=\"true\", histtype=\"step\", color=\"navy\", lw=3)\n",
    "ax3.set_xlabel(output_col)\n",
    "ax3.set_ylabel('log10')\n",
    "ax3.title.set_text(f\"log10-transformed {output_col} output data\\nfiltered by output_transform ops\")\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "\n",
    "Albrecht, B. A.  (1989).  Aerosols, cloud microphysics and fractional cloudiness.Sci-449ence,245, 12271230.\n",
    "\n",
    "Bodas-Salcedo, A., Mulcahy, J. P., Andrews, T., Williams, K. D., Ringer, M. A.,455Field, P. R., & Elsaesser, G. S.(2019).Strong Dependence of Atmospheric456Feedbacks on Mixed-Phase Microphysics and Aerosol-Cloud Interactions in457HadGEM3.Journal of Advances in Modeling Earth Systems,11(6), 17351758.458doi:  10.1029/2019MS001688\n",
    "\n",
    "Bogenschutz, P. A., Gettelman, A., Morrison, H., Larson, V. E., Craig, C., & Scha-460nen, D. P.(2013).Higher-order turbulence closure and its impact on Climate461Simulation in the Community Atmosphere Model.Journal of Climate,26(23),46296559676.  doi:  10.1175/JCLI-D-13-00075.1\n",
    "\n",
    "Danabasoglu, G., Lamarque, J.-F., Bacmeister, J., Bailey, D. A., DuVivier, A. K.,471Edwards, J., . . .  Strand, W. G.(2020).The Community Earth System Model472Version 2 (CESM2).Journal of Advances in Modeling Earth Systems,12(2),473e2019MS001916.  doi:  10.1029/2019MS001916\n",
    "\n",
    "Forbes, R. M., & Ahlgrimm, M.(2014, September).On the Representation of475High-Latitude Boundary Layer Mixed-Phase Cloud in the ECMWF Global Model.476Monthly Weather Review,142(9), 34253445.  doi:  10.1175/MWR-D-13-00325.1\n",
    "\n",
    "Gettelman, A.(2015, November).Putting the clouds back in aerosolcloud inter-478actions.Atmos. Chem. Phys.,15(21), 1239712411.doi:  10.5194/acp-15-12397479-2015480\n",
    "\n",
    "Gettelman, A., Bardeen, C. G., McCluskey, C. S., & Jarvinen, E.    (2020).    Simulat-481ing Observations of Southern Ocean Clouds and Implications for Climate.J. Adv.482Model. Earth Syst..  doi:  10.1029/2020JD032619483\n",
    "\n",
    "Gettelman, A., Hannay, C., Bacmeister, J. T., Neale, R. B., Pendergrass, A. G.,484Danabasoglu, G., . . .  Mills, M. J.(2019).High Climate Sensitivity in the Com-485munity Earth System Model Version 2 (CESM2).Geophysical Research Letters,48646(14), 83298337.  doi:  10.1029/2019GL083978487\n",
    "\n",
    "Gettelman, A., & Morrison, H.   (2015).   Advanced Two-Moment Bulk Microphysics488for Global Models. Part I: Off-Line Tests and Comparison with Other Schemes.J.489Climate,28(3), 12681287.  doi:  10.1175/JCLI-D-14-00102.1490\n",
    "\n",
    "Gettelman, A., Morrison, H., Santos, S., Bogenschutz, P., & Caldwell, P. M.   (2015).491Advanced Two-Moment Bulk Microphysics for Global Models. Part II: Global492Model Solutions and AerosolCloud Interactions.J. Climate,28(3), 12881307.493doi:  10.1175/JCLI-D-14-00103.1494\n",
    "\n",
    "Gettelman, A., & Sherwood, S. C.  (2016, October).  Processes Responsible for Cloud495Feedback.Curr Clim Change Rep, 111.  doi:  10.1007/s40641-016-0052-8\n",
    "\n",
    "Golaz, J.-C., Larson, V. E., & Cotton, W. R.(2002).A PDF-Based Model for497Boundary Layer Clouds. Part II: Model Results.J. Atmos. Sci.,59, 35523571.\n",
    "\n",
    "Hoose, C., Kristj ansson, J. E., Chen, J.-P., & Hazra, A.  (2010, March).  A Classical-499Theory-Based Parameterization of Heterogeneous Ice Nucleation by Mineral Dust,500Soot, and Biological Particles in a Global Climate Model.J. Atmos. Sci.,67(8),50124832503.  doi:  10.1175/2010JAS3425.1\n",
    "\n",
    "Iacono, M. J., Mlawer, E. J., Clough, S. A., & Morcrette, J.-J.  (2000).  Impact of an503improved longwave radiation model, RRTM, on the energy budget and thermody-504namic properties of the NCAR community climate model, CCM3.jgr,105(D11),50514,87314,890.\n",
    "\n",
    "Khairoutdinov, M. F., & Kogan, Y.  (2000).  A new cloud physics parameterization in507a large-eddy simulation model of marine stratocumulus.Monthly Weather Review,508128, 229243.\n",
    "\n",
    "Larson, V. E., Golaz, J.-C., & Cotton, W. R.(2002, December).Small-Scale and510Mesoscale Variability in Cloudy Boundary Layers:  Joint Probability Density Func-511tions.J. Atmos. Sci.,59(24), 35193539.   doi:  10.1175/1520-0469(2002)0593519:512SSAMVI2.0.CO;2\n",
    "\n",
    "Liu, X., & Penner, J. E.  (2005).  Ice Nucleation Parameterization for Global Models.514Meteor. Z.,14(499-514).\n",
    "\n",
    "Michibata, T., & Takemura, T.(2015, September).Evaluation of autoconversion520schemes in a single model framework with satellite observations.J. Geophys. Res.521Atmos.,120(18), 2015JD023818.  doi:  10.1002/2015JD023818\n",
    "\n",
    "Neale, R. B., Richter, J. H., & Jochum, M.(2008).The Impact of Convection on523ENSO: From a Delayed Oscillator to a Series of Events.J. Climate,21, 5904-+.doi:  10.1175/2008JCLI2244.1\n",
    "\n",
    "Pruppacher, H. R., & Klett, J. D.   (1997).Microphysics of Clouds and Precipitation526(Second ed.).  Kluwer Academic.\n",
    "\n",
    "Seifert, A., & Beheng, K. D.  (2001).  A double-moment parameterization for simulat-531ing autoconversion, accretion and selfcollection.Atmos. Res.,59-60, 265281.\n",
    "\n",
    "Shi, X., Liu, X., & Zhang, K.  (2015, February).  Effects of pre-existing ice crystals on536cirrus clouds and comparison between different ice nucleation parameterizations537with the Community Atmosphere Model (CAM5).Atmospheric Chemistry and538Physics,15(3), 15031520.  doi:  10.5194/acp-15-1503-2015\n",
    "\n",
    "Twomey, S.  (1977).  The influence of pollution on the shortwave albedo of clouds.J.553Atmos. Sci.,34(7), 11491152.\n",
    "\n",
    "Wang, Y., Liu, X., Hoose, C., & Wang, B.(2014, October).Different contact555angle distributions for heterogeneous ice nucleation in the Community Atmo-556spheric Model version 5.Atmos. Chem. Phys.,14(19), 1041110430.doi:55710.5194/acp-14-10411-2014\n",
    "\n",
    "Zhang, G. J., & McFarlane, N. A.    (1995).    Sensitivity of climate simulations to the559parameterization of cumulus convection in the Canadian Climate Center general560circulation model.Atmos. Ocean,33, 407446."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hackathon Challenges\n",
    "\n",
    "### Monday\n",
    "* Load the data\n",
    "* Create an exploratory visualization of the data\n",
    "* Test two different transformation and scaling methods\n",
    "* Test one dimensionality reduction method\n",
    "* Train a linear model\n",
    "* Train a decision tree ensemble method of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monday's code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday\n",
    "* Train a densely connected neural network\n",
    "* Train a convolutional or recurrent neural network (depends on problem)\n",
    "* Experiment with different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuesday's code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wednesday\n",
    "* Calculate three relevant evaluation metrics for each ML solution and baseline\n",
    "* Refine machine learning approaches and test additional hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wednesday's code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday \n",
    "* Evaluate two interpretation methods for your machine learning solution\n",
    "* Compare interpretation of baseline with your approach\n",
    "* Submit best results on project to leaderboard\n",
    "* Prepare 2 Google Slides on team's approach and submit them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thursday's code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultimate Submission Code\n",
    "Please insert your full data processing and machine learning pipeline code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
